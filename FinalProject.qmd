---
title: "Data Science for Public Policy Final Project"
subtitle: "Examining the Relationship Between Economic Status and Public Health Outcomes in the D.C. Area"
author: "Adriana Vance, Kyle Kim, Elena Koshkin, Kamiryn Rose"
execute:
  warning: false
format:
  html:
    embed-resources: true
---
```{r message=FALSE, warning=FALSE}
library(httr)
library(jsonlite)
library(tidyverse)
library(tidycensus)
library(purrr)
library(sf)
library(dplyr)
library(patchwork)
library(recipes)
library(ggplot2)
library(tidyclust)
library(tigris)
library(broom)
library(factoextra)
library(tmap)
library(mapproj)
library(leaflet)
```

## Part 01
```{r echo = false, message=FALSE, warning=FALSE}
#Read in CSV of CDC data
Health <- read_csv("PLACES.csv")

# Look at types of health outcome measures
Measures <- Health %>%
  group_by(Measure) %>%
  summarize(n = n())

MeasureIDs <- Health %>%
  group_by(MeasureId) %>%
  summarize(n = n())

# We want to look for current rates of asthma, heart disease, diabetes, stroke, and depression
Health <- Health %>%
  filter(
    MeasureId == "CASTHMA" |
      MeasureId == "CHD" |
      MeasureId == "DIABETES" |
      MeasureId == "STROKE" |
      MeasureId == "DEPRESSION")

ACSData <- load_variables(2021, "acs5") #browse to find variables
      
# Loading ACS Data (not working right now)
my_vars <- c(median_cost_ratio = "B25071_001E")


DC <- get_acs(geography = "tract",
                     variables = my_vars,
                     state = "DC", 
                     output = "wide",
                     survey = "acs5",
                     year = 2021,
                     geometry = TRUE)

MD <- get_acs(geography = "tract",
                     variables = my_vars,
                     state = "MD",
                     county = c("Montgomery", "Prince George's"),
                     output = "wide",
                     survey = "acs5",
                     year = 2021,
                     geometry = TRUE)

VA <- get_acs(geography = "tract",
                     variables = my_vars,
                     state = "VA",
                     county = "Fairfax County",
                     output = "wide",
                     survey = "acs5",
                     year = 2021,
                     geometry = TRUE)

All_states <- bind_rows(DC, MD, VA)


```

This is loading and exploring public health and demographic data, focusing on specific health measures and ACS variables for the DMV area.

#### Health Outcomes Distribution Map

```{r}
# Change geometry to be readable by SF

Health_map <- Health %>%
  st_as_sf(wkt = "Geolocation", remove = FALSE) %>%
  st_set_crs(value = 4326) # setting CRS

# Map health outcomes
Health_map %>%
  ggplot() +
  geom_sf(aes(color = MeasureId)) +
  labs(
    title = "Health Outcomes DMV Map",
    subtitle = "Distribution of Health Measures",
    caption = "CASTHMA = Current Asthma\nCHD = Coronary Heart Disease",
    color = "Health Measures ID"
  )

```
## Part 02
```{r echo=FALSE, warning=FALSE, message=FALSE}

#pulling tigris package tracts data

Maryland_tracts <- tracts(
state = "MD",
county = c("Montgomery", "Prince George's"),
cb = FALSE,
resolution = "500k",
year = 2010)

Virginia_tracts <- tracts(
  state = "VA",
  county = "Fairfax County",
  resolution = "500k", 
  year = 2010
)

DC_tracts <- tracts(
  state = "DC",
  resolution = "500k",
  year = 2010
)

DMV_tracts<- rbind_tigris(DC_tracts, Virginia_tracts, Maryland_tracts)

```

```{r echo=FALSE, warning=FALSE, message=FALSE}
#loading banks data 
banks <- read.csv("banks.csv")

# replace the white space with underscores and lower-case all of the letters in column names
names(banks) <- names(banks) |> 
  str_replace_all("\\s", "_") |> 
  str_to_lower()
```

NOTE: Necessary packages for the following code are "mapproj" and "tmap"
Run: install.packages("mapproj") and install.packages("tmap") if not already loaded
```{r echo=FALSE, warning=FALSE, message=FALSE}

#filter the data to rows about banks that have valid longitudes and latitudes
banks_locations <- banks |>
  filter(!is.na(longitude), !is.na(latitude))
#convert longitude and latitude columns into spatial geometries
banks_locations <- st_as_sf(banks_locations, coords = c("longitude", "latitude"))
#set CRS to 4326 (WGS 84)
banks_locations <- st_set_crs(banks_locations, value = 4326)
#check the CRS
st_crs(banks_locations)

#plot map using ggplot2
banks_locations |>
  ggplot() +
  geom_sf(
    aes(color = name), alpha = 0.4, size = 2)


# spatial join and census tracts 
#match CRS of both objects using the given CRS: 4326
banks_chloro <- st_transform(banks_locations, crs = st_crs(DMV_tracts))

#spatial join bank points and census tracts
banks_join <- st_join(DMV_tracts, banks_chloro, st_intersects) 

banks_merged_1 <- banks_join %>%
  group_by(GEOID10) %>%
  summarize(
    bank_count = sum(!is.na(name), na.rm = TRUE))

#join census tract back to new dataframe
banks_merged_1 <- st_join(DMV_tracts, banks_merged_1, join = st_intersects)

#trying to plot bank locations over a map of the census tracts 

#library(tmap)
#tm_shape(DMV_tracts) +
#tm_polygons()

#DMV_tracts_filter<- DMV_tracts %>%
 # select(GEOID10, geometry)

#plot(DMV_tracts_filter)

#tm_shape(DMV_tracts_filter) +
 # tm_polygons("banks_join")


# this map of bank location in DC works, but I'm not sure it's correct and it's not a choropleth
banks_join %>%
  ggplot()+ 
  geom_sf(data = DC_tracts) + 
  geom_sf(data = banks_locations, aes(color = ward)) 

#chloropleth

banks_merged_2 <- banks_merged_1 |>
  select(geometry, bank_count)

p1 <- banks_merged_2 %>%
  ggplot() +
  geom_sf(aes(fill = log1p(bank_count)), color = "white", size = 0.1) +
  scale_fill_gradient(low = "#81FFEF", high = "#F067B4", na.value = "white") +
  labs(fill = "Log(Bank Count)") +
  theme_void()

p1
  
```
# Banks Choropleth
```{r echo=FALSE, warning=FALSE, message=FALSE}

# trying to create a choropleth and it is not working lol
banks_merged <- banks_join %>%
  group_by(NAME10) %>%
  mutate(n = n()) %>%
  ungroup()
  
  
banks_merged_agg <- st_join(DC_tracts, banks_merged, join = st_intersects)  


# attempt 1
p1<- banks_merged_agg %>%
  
  ggplot() + geom_sf(data = DC_tracts) +
  geom_sf(aes(fill = n), size = 0.1) + coord_sf() +
  scale_x_continuous(breaks = 1:5) +
 scale_fill_gradient(
    low = "#90ee90", 
    high = "#F067B4",
    ) 
p1


# attempt 2
banks_merged_try <- banks_join %>%
  group_by(NAME10) %>%
  mutate(n = n()) %>%
  ungroup()

banks_merged_try %>%
  ggplot() +
  geom_sf(aes(fill = n, color = n, alpha = 0.2)) 

```

# Geospatial Analysis
```{r echo=FALSE, warning=FALSE, message=FALSE}

# looking at economic outcomes in relationship to distance to banks 
banking<- st_transform(banks_join, crs = 4326)
DC<- st_transform(DC_tracts, crs = 4326)

econ <- debt_tract_2 %>%
  st_as_sf(coords = c("INTPTLON10", "INTPTLAT10"), remove = FALSE) %>%
  st_set_crs(value = 4326) # setting CRS

banks_filtered<- st_join(banking, DC, left= FALSE)
banks_econ<- st_join(econ, st_buffer(banks_filtered, dist = 400))
max_banks_econ<- banks_econ %>%
  group_by(NAME10) %>%
  filter(DTI_ratio > 20) %>%
  summarize(n = n()) 

#looking at public health outcomes in relationship to distance to banks 

banking<- st_transform(banks_join, crs = 4326)
DC<- st_transform(DC_tracts, crs = 4326)

healthyy <- st_as_sf(Health2, coords = c("longitude", "latitude"))
healthyy <- st_set_crs(healthyy, value = 4326)
healthyy<- st_transform(healthyy, crs = 4326)

#Filter depression
healthyy <- healthyy %>%
  filter(short_question_text %in% c("Depression","Cancer (except skin)"))
      

#transforming so it matches for the spatial join
banks_filtered<- st_join(banking, DC, left= FALSE)


banks_health<- st_join(healthyy, st_buffer(banks_filtered, dist = 400))


max_banks<- banks_health %>%
  filter(short_question_text %in% "Depression") %>%
  group_by(NAME10.x) %>%
  summarize(n = n())
view(max_banks)


```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# loading debt to income ratio data

debt_to_income <- read.table("debt_to_income.txt", header = FALSE) 
# Have to manually name columns

colnames(debt_to_income) <- c('enterprise', 'record_num','state_postal_code', 'MSA', 'COUNTYFP', 'NAME10', 'percent_minority', 'median_income', 'MSA_median_income', 'tract_income_ratio', 'borrower_income','AMI', 'borrower_income_ratio', 'UPB','purpose_of_loan', 'fed_guarantee', 'num_borrowers', 'first_time_borrower', 'borrower_race_1', 'race_2', 'race_3', 'race_4', 'race_5', 'borrower_ethnicity', 'co_borrower_race_1', 'co_race_2', 'co_race_3', 'co_race_4', 'co_race_5',   'co_borrower_ethnicity', 'borrower_gender', 'co_borrower_gender', 'borrower_age', 'co_borrower_age', 'occupancy_code', 'rate_spread', 'HOEPA_status', 'property_type', 'lien_status', 'borrower_over_sixtytwo', 'co_borrower_over_sixtytwo', 'LTV_ratio', 'note_date', 'mortgage_term', 'num_units', 'interest_rate', 'note_amount', 'preapproval', 'application_channel', 'AUS_name', 'borrower_credscore_model', 'co_borrower_credscore_model', 'DTI_ratio', 'discount_points', 'rate_period', 'manufactured_home_ownership', 'property_value', 'rural_tract', 'lower_MS_delta', 'Mid_Appalachia', 'persistent_poverty_county', 'concentrated_poverty', 'high_opportunity_area', 'QOZ')

counties <- c(1, 59, 31, 33) # Name county vector to filter dataset to needed counties only 

debt_to_income <- debt_to_income %>%
  filter(MSA == 47900) 

debt_to_income <- debt_to_income %>%
  filter(COUNTYFP == counties) # Filtering to needed counties 

# Mutate dataset to match county names of TIGRIS shapefile
debt_to_income <- debt_to_income %>%
  mutate(COUNTYFP = 
    if_else(COUNTYFP == 1, "001", as.character(COUNTYFP)))

debt_to_income <- debt_to_income %>%
  mutate(COUNTYFP = 
           if_else(COUNTYFP == 59, "059", as.character(COUNTYFP)))
    
debt_to_income <- debt_to_income %>%
  mutate(COUNTYFP = 
           if_else(COUNTYFP == 31, "031", as.character(COUNTYFP)))

debt_to_income <- debt_to_income %>%
  mutate(COUNTYFP = 
           if_else(COUNTYFP == 33, "033", as.character(COUNTYFP)))

debt_to_income$NAME10 <- as.numeric(debt_to_income$NAME10)

DMV_tracts$NAME10 <- as.numeric(DMV_tracts$NAME10)

debt_to_income$NAME10 <- debt_to_income$NAME10 / 100

#Merging the datasets by census tract name
debt_tract_2 <- full_join(DMV_tracts, debt_to_income, by = "NAME10")

debt_tract_2 %>%
  ggplot() + 
  geom_sf()

# Setting CRS for geospatial visualizations 

debt_tract_2 <- debt_tract_2 %>%
  st_as_sf(coords = c("INTPTLON10", "INTPTLAT10"), remove = FALSE) %>%
  st_set_crs(value = 4326) # setting CRS

st_crs(debt_tract_2) # Checking CRS

debt_tract_2 <- st_transform(debt_tract_2, crs = 4326)

st_crs(debt_tract_2)

# Debt-to-income ratio Choropleth
p3 <- debt_tract_2 %>%
  ggplot() + 
  geom_sf(
    aes(
      fill = DTI_ratio), color = "White", size = 0.1) +
  scale_fill_gradient(
    low = "#81FFEF",
    high = "#F067B4",
    na.value = "white"
  ) +
  labs(
    fill = "Debt to Income Ratio"
  ) +
  theme_void()

p3

```

### Using Leaflet to create an interactive map of debt to income ratios in the DMV
```{r echo=FALSE, warning=FALSE, message=FALSE}

# Load required libraries
library(leaflet)


# Create a new variable in our spatial object for fill color
debt_tract_2$FillColor <- colorQuantile("YlOrRd", debt_tract_2$DTI_ratio)(debt_tract_2$DTI_ratio)

# Create a leaflet map
leaflet(debt_tract_2) %>%
  
  # Add the polygons from the spatial object
  addPolygons(
    fillColor = ~FillColor,
    fillOpacity = 0.7,
    color = "white",
    weight = 1,
    popup = ~paste("Debt-to-Income Ratio: ", DTI_ratio)
  ) %>%
  
  # Add legend
  addLegend(
    "bottomright",
    pal = colorQuantile("YlOrRd", debt_tract_2$DTI_ratio),
    values = ~debt_tract_2$DTI_ratio,
    title = "Debt-to-Income Ratio",
    opacity = 1
  )


```


```{r echo=FALSE, warning=FALSE, message=FALSE}
#Merged CDC Places dataset with census tracts and made graph and choropleths

#Read in CSV of CDC data
Health1 <- read_csv("PLACES.csv")

#Clean data and get long and lat columns
Health2 <- Health1 %>%
  separate(col = Geolocation, into = c("point", "coordinates"), sep = " ", extra = "merge", remove = FALSE) |>
  separate(col = coordinates, into = c("longitude", "latitude"), sep = " ", remove = TRUE)

Health2 <- Health2 %>%
  mutate(longitude = gsub("[()]", "", longitude),
         latitude = gsub("[()]", "", latitude))

names(Health2) <- names(Health2) |> 
  str_to_lower()

#Use consistent health measures: CASTHMA, CHD, Depression, Diabetes, Stroke

Health3 <- Health2 %>%
  filter(measureid %in% c("CASTHMA", "CHD", "DIABETES", "STROKE", "DEPRESSION") &
           complete.cases(longitude, latitude))

#convert longitude and latitude columns into spatial geometries
sf_Health <- st_as_sf(Health3, coords = c("longitude", "latitude"))
#set CRS to 4326 (WGS 84)
sf_Health <- st_set_crs(sf_Health, value = 4326)
#check the CRS
st_crs(sf_Health)

#plot map using ggplot2
sf_Health |>
  ggplot() +
  geom_sf(
    aes(color = short_question_text), alpha = 0.4, size = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Perform a Spatial Join and Create Choropleth

#match cRS
sf_Health2 <- st_transform(sf_Health, crs = st_crs(DMV_tracts))

#spatial_join health points and census tracts
Health_join <- st_join(sf_Health2, DMV_tracts, st_intersects)

#calculate the count of cancer and depression in new dataframe
health_merged <- Health_join |>
  group_by(NAME10) |>
  mutate(
    calculated_value = totalpopulation * (data_value / 100)
  )

#join census tract back to new dataframe
health_merged2 <- st_join(DMV_tracts, health_merged, join = st_intersects)

#create choropleth maps
p4 <- health_merged |>
  ggplot() +
  geom_sf(
    aes(
      fill = calculated_value), color = "white", size = 0.1) +
  scale_fill_gradient(
    low = "#81FFEF", 
    high = "#F067B4",
    na.value = "white"
  ) +
  labs(
    fill = "Health Measures Count") +
  theme_void()

p4

combined_plot <- p3 + p4

combined_plot

```

#### Merging Health and Debt-to-Income dataset
```{r echo=FALSE, warning=FALSE, message=FALSE}

#Merging health dataset with debt_tract_2 

#Converting long and lat coordinates to sf objects
debt_tract_2_sf <- st_as_sf(debt_tract_2, coords = c("INTPTLON10", "INTPTLAT10"), crs = 4326)

# Convert 'Geolocation' column to an sf object
Health_sf <- st_as_sf(Health, wkt = "Geolocation", crs = 4326)

#Confirm if health and debt use the same coordinate reference systems (crs) 

#They do not. 
st_crs(debt_tract_2_sf)
st_crs(Health_sf)

#Transform debt dataset to match health
debt_tract_2_sf <- st_transform(debt_tract_2_sf, st_crs(Health_sf))

#Reconfirm if they have the same crs.
#Now they do.
st_crs(debt_tract_2_sf)
st_crs(Health_sf)

#Spatial Join
health_debt <- st_join(debt_tract_2_sf, Health_sf, join = st_intersects)

```

#### Machine Learning Model 

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tidymodels)
set.seed(102102938)

split <- initial_split(data = debt_to_income, prop = 0.75)

debt_train <- training(x = split)
debt_test <- testing(x = split)

## Health outcome for machine learning model will be percentage of instances of depression in a censust tract

```

### Machine Learning Model #1: Predicting percentage of minorities in a census tract using the single family loan data
```{r echo=FALSE, warning=FALSE, message=FALSE}

debt_rec <- recipe(percent_minority ~ borrower_income + borrower_age + borrower_income_ratio + tract_income_ratio + DTI_ratio + interest_rate + note_amount, data = debt_train) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_corr(all_numeric_predictors())

# Creating tuning grid for lasso model
lasso_grid <- grid_regular(penalty())

# LASSO model
lasso_mod <- linear_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")

# LASSO workflow
lasso_wf <- workflow() %>%
  add_recipe(debt_rec) %>%
  add_model(lasso_mod) 

folds <- vfold_cv(data = debt_train, v = 10, repeats = 1)

# LASSO fit
lasso_fit <- lasso_wf %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid, 
    metrics = metric_set(rmse, mae), 
    control = control_grid(save_pred = TRUE))

# Evaluating models
lasso_metrics <- lasso_fit %>%
  collect_metrics(summarize = TRUE) 

lasso_fit %>%
  select_best(metric = "rmse")

# The RMSE of this model's best fit is around 22. 

```

### Machine Learning Model #2: Predicting rates of depression in a census tract using economic predictors from the debt-to-income dataset

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(randomForest)
library(caret)
library(tidymodels)
# Filtering dataset for second machine learning  model 


# We want only observations for rates of depression, and to exclude columns that have all values as NA or that are not interpretable by random forest modeling
depression_debt <- health_debt %>%
  drop_na(Data_Value) %>%
  filter(MeasureId == "DEPRESSION") %>%
  select(-Data_Value_Footnote, -Data_Value_Footnote_Symbol) %>%
  st_drop_geometry()

# Omit all NA values from dataset
depression_debt <- na.omit(depression_debt)


set.seed(12122023)
split2 <- initial_split(data = depression_debt, prop = 0.8)

depression_train2 <- training(x = split2)
depression_test2 <- testing(x = split2)


# Train the initial randomForest model with specified predictors
rf_mod <- randomForest(Data_Value ~ borrower_income + borrower_age + borrower_income_ratio + tract_income_ratio + DTI_ratio + interest_rate + note_amount + property_value + percent_minority, data = depression_train2)

rf_mod 
# This model only explains about 77.6% of the variance. After filtering out observations that are not interpretable by RF modeling, we will try a random forest model with all predictors

# Trying some tuning to see if we can find the best amount of mtrys to use for the model
bestmtry <- tuneRF(depression_train2,depression_train2$Data_Value,stepFactor = 2, improve = 0.01, trace = TRUE, plot = T, doBest = TRUE) 

# tuneRF shows that the best amount of mtrys is 32. Running random forest model again with 32 mtrys to see if it further optimizes the model. 
best_mtry <- 32

rf_mod3 <- randomForest(Data_Value ~., data = depression_train2, mtry = best_mtry)

rf_mod3
# This model shows great improvement from the previous, explaining 99.99% of the variance. We can use this model to predict health outcomes on the testing dataset. 

predicted_values <- predict(rf_mod3, newdata = depression_test2, type = "class")

test_predictions <- bind_cols(
  depression_test2, predicted_values)

test_predictions <- test_predictions %>%
  rename(.pred = ...99)

metrics(test_predictions, truth = Data_Value, estimate = .pred)

prediction_table <- tibble(test_predictions$Data_Value, test_predictions$.pred)

```
# Cluster Analysis
```{r echo=FALSE, warning=FALSE, message=FALSE}
# ATTEMPT

dti_data <- debt_to_income %>%
  select(NAME10, DTI_ratio)

dti_pca_rec <- recipe(~ ., data = dti_data) %>%
  step_pca(all_numeric(), id = "pca") %>%
  prep(data = dti_data) %>%
  bake(new_data = dti_data) 


viz_1 <- dti_pca_rec %>%
  ggplot() +
  geom_point(
    mapping = aes(x = PC1, y = PC2),
    alpha = 0.5
  ) +
  theme_minimal()

viz_1 


#create the function 
debt_pca_fun<- function(DTI, df){
  debt_pca<- df %>%
    replace(is.na(.), 0) %>%
    filter(DTI_ratio == DTI) 
  
debt_pca_rec <- recipe(~ ., data = dti_data) %>%
    step_pca(all_numeric(), num_comp = 2) %>%
    prep(data = dti_data) %>%
    bake(new_data = dti_data) %>%
    select(PC1, PC2)
    

kmeans_rec<- recipe(~ ., data = dti_data) %>%
  step_select(all_numeric())
  
  debt_pca_spec <- k_means(
  num_clusters = 4
) %>%
  set_engine("stats", nstart = 100)

debt_pca_workflow <- workflow(
  preprocessor = kmeans_rec, 
  spec = debt_pca_spec
)

final_fit <- debt_pca_workflow %>%
  fit(data = dti_data)

debt_clusters <- 
  bind_cols(dti_data, debt_pca_rec, cluster = final_fit %>%
    extract_cluster_assignment() %>%
    pull(.cluster) )

return(debt_clusters)
}

#lastly, mapping the output
DTI<- 1:100
set.seed(20220413)
final_result <- map_dfr(.x = DTI, .f = debt_pca_fun, df = debt_to_income)
print(final_result)
  


```

```{r echo=FALSE, warning=FALSE, message=FALSE}
clust_plot <- final_result %>%
  ggplot() +
  geom_point(
    mapping = aes(x = PC1, y = PC2),
    alpha = 0.5
  ) +
  labs(
    title = "DTI",
    x = "PC1",
    y = "PC2"
  ) + 
  theme_classic()

clust_plot
```


```{r echo=FALSE, warning=FALSE, message=FALSE}

set.seed(20220414)
fviz_nbclust(
  dti_data, 
  FUN = hcut, 
  k.max = 10, 
  method = "wss", 
  hc_func = "hclust", 
  hc_method = "ward.D2", 
  hc_metric = "euclidean"
)

set.seed(20220414)
fviz_nbclust(
  dti_data,
  FUN = hcut,
  k.max = 10,
  method = "silhouette",
  hc_func = "hclust",
  hc_method = "ward.D2",
  hc_metric = "euclidean"
)

d <- dist(dti_data, method = "euclidean")
hclust_euc<- hclust(d, "ward.D2")
plot(hclust_euc, cex = 0.6, hang = -1, main = "Cluster Dendogram")
rect.hclust(hclust_euc, k = 4, border = "purple")

```